{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/conda_envs/project1/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# git clone https://github.com/ZIZUN/korean-malicious-comments-dataset\n",
    "\n",
    "df= pd.read_csv('./korean-malicious-comments-dataset/Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content\\tlable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이종석 한효주 나오는 드라마 이후로 드라마 안봤다. 2년전인가?? 좀 신선했었지. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>씨바알..노무노무 술프노... 오늘 저녁은 꽂등심이다ㅠㅜ\\t0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>짱깨 꺼라ㅡ패쓰\\t0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그들의 사생활 ~ 고인이된 설리를 위해서라도 모두 조용하길 지금 누굴 탓한다고 무슨...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>아무리 법이 뭣같아도 무슨 자격으로 개인의 신상정보를 불특정 다수에게 공개하는지 도...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>이거 보다 더한 막장의 드라마도 넋놓고 보면서 무슨?\\t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>머...제네시스..올라프에디션?\\t1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>항상 여자로 ㅡ ㅡ 저지랄 들이야 남자들 벗겨봐라\\t0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>첫번째 이유가 ㄹㅇ 맞지특히나 뉴스나 기사 몇줄읽은 학생들끼리 대화해도 서로 존나 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Lg폰 누가쓰냐 gps도 못잡는폰 쓰래기 통에나 버려라\\t0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         content\\tlable\n",
       "0     이종석 한효주 나오는 드라마 이후로 드라마 안봤다. 2년전인가?? 좀 신선했었지. ...\n",
       "1                    씨바알..노무노무 술프노... 오늘 저녁은 꽂등심이다ㅠㅜ\\t0\n",
       "2                                           짱깨 꺼라ㅡ패쓰\\t0\n",
       "3     그들의 사생활 ~ 고인이된 설리를 위해서라도 모두 조용하길 지금 누굴 탓한다고 무슨...\n",
       "4     아무리 법이 뭣같아도 무슨 자격으로 개인의 신상정보를 불특정 다수에게 공개하는지 도...\n",
       "...                                                 ...\n",
       "9995                   이거 보다 더한 막장의 드라마도 넋놓고 보면서 무슨?\\t1\n",
       "9996                               머...제네시스..올라프에디션?\\t1\n",
       "9997                     항상 여자로 ㅡ ㅡ 저지랄 들이야 남자들 벗겨봐라\\t0\n",
       "9998  첫번째 이유가 ㄹㅇ 맞지특히나 뉴스나 기사 몇줄읽은 학생들끼리 대화해도 서로 존나 ...\n",
       "9999                  Lg폰 누가쓰냐 gps도 못잡는폰 쓰래기 통에나 버려라\\t0\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sep='\\t' 를 통해서 탭 구분자로 불러오기\n",
    "df= pd.read_csv('./korean-malicious-comments-dataset/Dataset.csv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>lable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이종석 한효주 나오는 드라마 이후로 드라마 안봤다. 2년전인가?? 좀 신선했었지. ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>씨바알..노무노무 술프노... 오늘 저녁은 꽂등심이다ㅠㅜ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>짱깨 꺼라ㅡ패쓰</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그들의 사생활 ~ 고인이된 설리를 위해서라도 모두 조용하길 지금 누굴 탓한다고 무슨...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>아무리 법이 뭣같아도 무슨 자격으로 개인의 신상정보를 불특정 다수에게 공개하는지 도...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>이거 보다 더한 막장의 드라마도 넋놓고 보면서 무슨?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>머...제네시스..올라프에디션?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>항상 여자로 ㅡ ㅡ 저지랄 들이야 남자들 벗겨봐라</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>첫번째 이유가 ㄹㅇ 맞지특히나 뉴스나 기사 몇줄읽은 학생들끼리 대화해도 서로 존나 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Lg폰 누가쓰냐 gps도 못잡는폰 쓰래기 통에나 버려라</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  lable\n",
       "0     이종석 한효주 나오는 드라마 이후로 드라마 안봤다. 2년전인가?? 좀 신선했었지. ...    0.0\n",
       "1                       씨바알..노무노무 술프노... 오늘 저녁은 꽂등심이다ㅠㅜ    0.0\n",
       "2                                              짱깨 꺼라ㅡ패쓰    0.0\n",
       "3     그들의 사생활 ~ 고인이된 설리를 위해서라도 모두 조용하길 지금 누굴 탓한다고 무슨...    1.0\n",
       "4     아무리 법이 뭣같아도 무슨 자격으로 개인의 신상정보를 불특정 다수에게 공개하는지 도...    1.0\n",
       "...                                                 ...    ...\n",
       "9995                      이거 보다 더한 막장의 드라마도 넋놓고 보면서 무슨?    1.0\n",
       "9996                                  머...제네시스..올라프에디션?    1.0\n",
       "9997                        항상 여자로 ㅡ ㅡ 저지랄 들이야 남자들 벗겨봐라    0.0\n",
       "9998  첫번째 이유가 ㄹㅇ 맞지특히나 뉴스나 기사 몇줄읽은 학생들끼리 대화해도 서로 존나 ...    0.0\n",
       "9999                     Lg폰 누가쓰냐 gps도 못잡는폰 쓰래기 통에나 버려라    0.0\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns=['text','label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>이종석 한효주 나오는 드라마 이후로 드라마 안봤다. 2년전인가?? 좀 신선했었지. ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>씨바알..노무노무 술프노... 오늘 저녁은 꽂등심이다ㅠㅜ</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>짱깨 꺼라ㅡ패쓰</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>그들의 사생활 ~ 고인이된 설리를 위해서라도 모두 조용하길 지금 누굴 탓한다고 무슨...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>아무리 법이 뭣같아도 무슨 자격으로 개인의 신상정보를 불특정 다수에게 공개하는지 도...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>이거 보다 더한 막장의 드라마도 넋놓고 보면서 무슨?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>머...제네시스..올라프에디션?</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>항상 여자로 ㅡ ㅡ 저지랄 들이야 남자들 벗겨봐라</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>첫번째 이유가 ㄹㅇ 맞지특히나 뉴스나 기사 몇줄읽은 학생들끼리 대화해도 서로 존나 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Lg폰 누가쓰냐 gps도 못잡는폰 쓰래기 통에나 버려라</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     이종석 한효주 나오는 드라마 이후로 드라마 안봤다. 2년전인가?? 좀 신선했었지. ...    0.0\n",
       "1                       씨바알..노무노무 술프노... 오늘 저녁은 꽂등심이다ㅠㅜ    0.0\n",
       "2                                              짱깨 꺼라ㅡ패쓰    0.0\n",
       "3     그들의 사생활 ~ 고인이된 설리를 위해서라도 모두 조용하길 지금 누굴 탓한다고 무슨...    1.0\n",
       "4     아무리 법이 뭣같아도 무슨 자격으로 개인의 신상정보를 불특정 다수에게 공개하는지 도...    1.0\n",
       "...                                                 ...    ...\n",
       "9995                      이거 보다 더한 막장의 드라마도 넋놓고 보면서 무슨?    1.0\n",
       "9996                                  머...제네시스..올라프에디션?    1.0\n",
       "9997                        항상 여자로 ㅡ ㅡ 저지랄 들이야 남자들 벗겨봐라    0.0\n",
       "9998  첫번째 이유가 ㄹㅇ 맞지특히나 뉴스나 기사 몇줄읽은 학생들끼리 대화해도 서로 존나 ...    0.0\n",
       "9999                     Lg폰 누가쓰냐 gps도 못잡는폰 쓰래기 통에나 버려라    0.0\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(sentence: str) -> str:\n",
    "    return (\n",
    "        \"다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n\"\n",
    "        \"### 문장:\\n\"\n",
    "        f\"{sentence}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 컬럼 업데이트\n",
    "df[\"text\"] = df[\"text\"].apply(build_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1.0    4992\n",
       "0.0    4983\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n이종석 한효주 나오...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n씨바알..노무노무 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n짱깨 꺼라ㅡ패쓰</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n아무리 법이 뭣같아...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n다음도 들어와라하고...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9970</th>\n",
       "      <td>다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n이거 보다 더한 막...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9971</th>\n",
       "      <td>다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n머...제네시스.....</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9972</th>\n",
       "      <td>다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n항상 여자로 ㅡ ㅡ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n첫번째 이유가 ㄹㅇ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9974</th>\n",
       "      <td>다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\nLg폰 누가쓰냐 g...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9475 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n이종석 한효주 나오...    0.0\n",
       "1     다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n씨바알..노무노무 ...    0.0\n",
       "2          다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n짱깨 꺼라ㅡ패쓰    0.0\n",
       "4     다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n아무리 법이 뭣같아...    1.0\n",
       "5     다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n다음도 들어와라하고...    0.0\n",
       "...                                                 ...    ...\n",
       "9970  다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n이거 보다 더한 막...    1.0\n",
       "9971  다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n머...제네시스.....    1.0\n",
       "9972  다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n항상 여자로 ㅡ ㅡ...    0.0\n",
       "9973  다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n첫번째 이유가 ㄹㅇ...    0.0\n",
       "9974  다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\nLg폰 누가쓰냐 g...    0.0\n",
       "\n",
       "[9475 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df=df.sample(n=500,random_state=42)\n",
    "\n",
    "train_df=df.drop(valid_df.index)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5825</th>\n",
       "      <td>다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n고주원 커플방송 늘...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5171</th>\n",
       "      <td>다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n야이 빙신아 천조국...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6041</th>\n",
       "      <td>다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n근대 이와중에 박나...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n우리찜니 넘조아</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n장모님과 연 끊고 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5896</th>\n",
       "      <td>다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n꺼져</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6551</th>\n",
       "      <td>다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n인정할건인정해라 닥...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n탑이랑 걸렸을 때 ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n존예고만 어디가 안...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n이런새끼특징 지가 ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "5825  다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n고주원 커플방송 늘...    1.0\n",
       "5171  다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n야이 빙신아 천조국...    0.0\n",
       "6041  다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n근대 이와중에 박나...    0.0\n",
       "107        다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n우리찜니 넘조아    1.0\n",
       "3422  다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n장모님과 연 끊고 ...    0.0\n",
       "...                                                 ...    ...\n",
       "5896             다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n꺼져    0.0\n",
       "6551  다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n인정할건인정해라 닥...    0.0\n",
       "450   다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n탑이랑 걸렸을 때 ...    1.0\n",
       "1593  다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n존예고만 어디가 안...    1.0\n",
       "856   다음 문장이 긍정인지 부정인지 판단하세요.\\n\\n### 문장:\\n이런새끼특징 지가 ...    0.0\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=train_df.reset_index(drop=True)\n",
    "valid_df=valid_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= datasets.DatasetDict({\n",
    "    'train': datasets.Dataset.from_pandas(train_df),\n",
    "    'valid': datasets.Dataset.from_pandas(valid_df)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 9475\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "_MAX_LEN = int(os.getenv(\"MAX_LEN\", 512))\n",
    "\n",
    "\n",
    "def get_dataset(data, tokenizer, max_len):\n",
    "    def _encode(batch):\n",
    "        enc = tokenizer(batch[\"text\"],\n",
    "                        truncation=True,\n",
    "                        padding=\"max_length\",\n",
    "                        max_length=max_len)\n",
    "        # 라벨을 int64, shape [B]\n",
    "        enc[\"labels\"] = np.array(batch[\"label\"], dtype=np.int64)\n",
    "        return enc\n",
    "\n",
    "    tokenised = data.map(_encode, batched=True, remove_columns=[\"text\", \"label\"])\n",
    "    tokenised.set_format(\"torch\",\n",
    "                         columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "    return tokenised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/conda_envs/project1/lib/python3.11/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Trainer, TrainingArguments, AutoTokenizer, DataCollatorWithPadding\n",
    "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at skt/kobert-base-v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_path='skt/kobert-base-v1'\n",
    "\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_path, num_labels=2, problem_type=\"single_label_classification\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, config=config)\n",
    "tokenizer  = AutoTokenizer.from_pretrained(model_path, use_fast=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.id2label = {0: \"none\", 1: \"toxic\"}\n",
    "model.config.label2id = {v: k for k, v in model.config.id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KoBERT 모델의 경우\n",
    "targets = [\"query\", \"key\", \"value\"]\n",
    "\n",
    "lora_cfg = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    target_modules=targets)\n",
    "\n",
    "\n",
    "model = get_peft_model(model, lora_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): BertForSequenceClassification(\n",
       "      (bert): BertModel(\n",
       "        (embeddings): BertEmbeddings(\n",
       "          (word_embeddings): Embedding(8002, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(512, 768)\n",
       "          (token_type_embeddings): Embedding(2, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): BertEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x BertLayer(\n",
       "              (attention): BertAttention(\n",
       "                (self): BertSdpaSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=16, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=16, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): BertSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): BertIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): BertOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (pooler): BertPooler(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (activation): Tanh()\n",
       "        )\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=2, bias=True)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 9475/9475 [00:03<00:00, 2948.79 examples/s]\n",
      "Map: 100%|██████████| 500/500 [00:00<00:00, 3215.53 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds = get_dataset(data, tokenizer, _MAX_LEN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 9475\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "        output_dir='model-checkpoints/kobert',\n",
    "        per_device_train_batch_size=128,\n",
    "        per_device_eval_batch_size=16,\n",
    "        num_train_epochs=20,\n",
    "        learning_rate=5e-5,\n",
    "        fp16=True,\n",
    "        eval_strategy=\"steps\",\n",
    "        save_strategy=\"steps\",\n",
    "        logging_steps=1,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_loss\",\n",
    "        save_steps=50,\n",
    "        eval_steps=50,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartCollator(DataCollatorWithPadding):\n",
    "    def __call__(self, features):\n",
    "        batch = super().__call__(features)\n",
    "        # BERT류만 전체 0으로 세팅\n",
    "        if \"token_type_ids\" in batch:\n",
    "            batch[\"token_type_ids\"].zero_()  \n",
    "        return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = SmartCollator(tokenizer, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "from typing import Dict, Tuple\n",
    "import numpy as np\n",
    "\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "accuracy_metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred                      # logits: [B,2], labels: [B]\n",
    "\n",
    "    preds  = logits.argmax(axis=-1)                 # 클래스 0/1\n",
    "    labels = labels.astype(np.int64)\n",
    "\n",
    "    acc = accuracy_metric.compute(predictions=preds, references=labels)[\"accuracy\"]\n",
    "    f1  = f1_metric.compute(predictions=preds, references=labels,\n",
    "                            average=\"weighted\")[\"f1\"]\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=ds[\"train\"],\n",
    "        eval_dataset=ds[\"valid\"],\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=lambda p: compute_metrics(p),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1500/1500 07:12, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.699500</td>\n",
       "      <td>0.691547</td>\n",
       "      <td>0.506000</td>\n",
       "      <td>0.461378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.697000</td>\n",
       "      <td>0.690152</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.543510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.656200</td>\n",
       "      <td>0.684172</td>\n",
       "      <td>0.592000</td>\n",
       "      <td>0.585416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.669400</td>\n",
       "      <td>0.676839</td>\n",
       "      <td>0.586000</td>\n",
       "      <td>0.553929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.668700</td>\n",
       "      <td>0.640544</td>\n",
       "      <td>0.648000</td>\n",
       "      <td>0.633015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.847800</td>\n",
       "      <td>0.582541</td>\n",
       "      <td>0.682000</td>\n",
       "      <td>0.675640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.572100</td>\n",
       "      <td>0.561169</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>0.697870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.578200</td>\n",
       "      <td>0.517711</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.755610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.174900</td>\n",
       "      <td>0.462164</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.775799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.595900</td>\n",
       "      <td>0.454235</td>\n",
       "      <td>0.786000</td>\n",
       "      <td>0.785970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.450800</td>\n",
       "      <td>0.444877</td>\n",
       "      <td>0.796000</td>\n",
       "      <td>0.795961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.204500</td>\n",
       "      <td>0.457771</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.788047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.538200</td>\n",
       "      <td>0.444852</td>\n",
       "      <td>0.796000</td>\n",
       "      <td>0.795108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.536600</td>\n",
       "      <td>0.439633</td>\n",
       "      <td>0.794000</td>\n",
       "      <td>0.793044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.044800</td>\n",
       "      <td>0.422862</td>\n",
       "      <td>0.804000</td>\n",
       "      <td>0.803937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.462800</td>\n",
       "      <td>0.432617</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.799126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>0.476600</td>\n",
       "      <td>0.431445</td>\n",
       "      <td>0.798000</td>\n",
       "      <td>0.797170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.092700</td>\n",
       "      <td>0.424268</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>0.801378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>0.417000</td>\n",
       "      <td>0.419585</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>0.801464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.422900</td>\n",
       "      <td>0.421582</td>\n",
       "      <td>0.796000</td>\n",
       "      <td>0.795312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>0.184200</td>\n",
       "      <td>0.420836</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>0.791198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.437300</td>\n",
       "      <td>0.409924</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.809891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>0.565300</td>\n",
       "      <td>0.408138</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.809806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.343800</td>\n",
       "      <td>0.417970</td>\n",
       "      <td>0.796000</td>\n",
       "      <td>0.795108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>0.532500</td>\n",
       "      <td>0.420102</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.798510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.429300</td>\n",
       "      <td>0.405548</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.809806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>0.410229</td>\n",
       "      <td>0.804000</td>\n",
       "      <td>0.803509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.473300</td>\n",
       "      <td>0.402809</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.809852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>0.425200</td>\n",
       "      <td>0.405981</td>\n",
       "      <td>0.804000</td>\n",
       "      <td>0.803717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.246600</td>\n",
       "      <td>0.404648</td>\n",
       "      <td>0.806000</td>\n",
       "      <td>0.805749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1500, training_loss=0.5190828965951999, metrics={'train_runtime': 433.3719, 'train_samples_per_second': 437.269, 'train_steps_per_second': 3.461, 'total_flos': 5.0375484082176e+16, 'train_loss': 0.5190828965951999, 'epoch': 20.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
